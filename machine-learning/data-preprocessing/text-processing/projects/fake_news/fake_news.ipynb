{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Detection\n",
    "> Problem\n",
    "> - create a model to detect fake news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy, re, nltk, gensim\n",
    "\n",
    "from spacy import displacy, tokenizer\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import gensim.corpora as corpora\n",
    "\n",
    "from gensim.models import CoherenceModel, LsiModel, TfidfModel\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot options\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "default_plot_colour = \"#00bfbf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"fake_news_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure we have the appropriate numbers of rows in each group\n",
    "data['fake_or_factual'].value_counts().plot(kind='bar', color=default_plot_colour)\n",
    "plt.title('Fake vs Factual News')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xlabel('Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS Tagging - Part of Speech Tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in fake and factual news\n",
    "fake_news = data[data['fake_or_factual'] == 'Fake News']\n",
    "factual_news = data[data['fake_or_factual'] == 'Factual News']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_spacy_doc = list(nlp.pipe(fake_news['text']))\n",
    "factual_spacy_doc = list(nlp.pipe(factual_news['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_token_tags(doc: spacy.tokens.doc.Doc):\n",
    "    return [(i.text, i.ent_type_, i.pos_) for i in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tags_df = []\n",
    "columns = [\"token\", \"ner_tag\", \"pos_tag\"]\n",
    "for ix, doc in enumerate(fake_spacy_doc):\n",
    "    tags = extract_token_tags(doc)\n",
    "    tags_df = pd.DataFrame(tags, columns=columns)\n",
    "    fake_tags_df.append(tags_df)\n",
    "\n",
    "fake_tags_df = pd.concat(fake_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_tags_df = []\n",
    "for ix, doc in enumerate(factual_spacy_doc):\n",
    "    tags = extract_token_tags(doc)\n",
    "    tags_df = pd.DataFrame(tags, columns=columns)\n",
    "    factual_tags_df.append(tags_df)\n",
    "    \n",
    "factual_tags_df = pd.concat(factual_tags_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token frequency count\n",
    "pos_counts_fake = fake_tags_df.groupby(['token', 'pos_tag']).size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "pos_counts_fake.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token frequency count\n",
    "pos_counts_factual = factual_tags_df.groupby(['token', 'pos_tag']).size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "pos_counts_factual.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency of individual pos tags (noun, verb, etc)\n",
    "pos_counts_fake.groupby('pos_tag')['token'].count().sort_values(ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency of individual pos tags (noun, verb, etc)\n",
    "pos_counts_factual.groupby('pos_tag')['token'].count().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if specific nouns are more common in fake news than factual news\n",
    "pos_counts_fake[pos_counts_fake['pos_tag'] == 'NOUN'][:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if specific nouns are more common in fake news than factual news\n",
    "pos_counts_factual[pos_counts_factual['pos_tag'] == 'NOUN'][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_entities_fake = fake_tags_df[fake_tags_df['ner_tag'] != ''].groupby([ 'token', 'ner_tag']).size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "top_entities_fake.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_entities_factual = factual_tags_df[factual_tags_df['ner_tag'] != ''].groupby([ 'token', 'ner_tag']).size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "top_entities_factual.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_palette = {\n",
    "    \"ORG\": sns.color_palette(\"Set2\").as_hex()[0],\n",
    "    \"GPE\": sns.color_palette(\"Set2\").as_hex()[1],\n",
    "    \"NORP\": sns.color_palette(\"Set2\").as_hex()[2],\n",
    "    \"PERSON\": sns.color_palette(\"Set2\").as_hex()[3],\n",
    "    \"DATE\": sns.color_palette(\"Set2\").as_hex()[4],\n",
    "    \"CARDINAL\": sns.color_palette(\"Set2\").as_hex()[5],\n",
    "    \"LOC\": sns.color_palette(\"Set2\").as_hex()[6],\n",
    "    \"PERCENT\": sns.color_palette(\"Set2\").as_hex()[7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x=\"count\",\n",
    "    y=\"token\",\n",
    "    hue=\"ner_tag\",\n",
    "    palette=ner_palette,\n",
    "    data=top_entities_fake[:10],\n",
    "    orient=\"h\",\n",
    "    dodge=False\n",
    ").set_title(\"Top Named Entities in Fake News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x=\"count\",\n",
    "    y=\"token\",\n",
    "    hue=\"ner_tag\",\n",
    "    palette=ner_palette,\n",
    "    data=top_entities_factual[:10],\n",
    "    orient=\"h\",\n",
    "    dodge=False\n",
    ").set_title(\"Top Named Entities in Factual News\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = {\n",
    "    \"first_hyphen_in_text\": r\"^[^-]*-\\s\",\n",
    "    \"no_punctuation\": r\"[^\\w\\s]\",\n",
    "}\n",
    "\n",
    "data[\"text_clean\"] = data.apply(\n",
    "    lambda x: re.sub(patterns[\"first_hyphen_in_text\"], \"\", x[\"text\"]), axis=1\n",
    ")\n",
    "\n",
    "data[\"text_clean\"] = data[\"text_clean\"].str.lower()\n",
    "\n",
    "data[\"text_clean\"] = data[\"text_clean\"].apply(\n",
    "    lambda x: re.sub(patterns[\"no_punctuation\"], \"\", x)\n",
    ")\n",
    "\n",
    "en_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "data[\"text_clean\"] = data[\"text_clean\"].apply(\n",
    "    lambda x: \" \".join([word for word in x.split() if word not in en_stopwords])\n",
    ")\n",
    "\n",
    "data[\"text_clean\"] = data.apply(\n",
    "    lambda x: word_tokenize(x[\"text_clean\"]), axis=1\n",
    ")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "data['text_clean'] = data['text_clean'].apply(lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-grams\n",
    "tokens_clean = sum(data['text_clean'], [])\n",
    "\n",
    "unigram = (pd.Series(nltk.ngrams(tokens_clean, 1)).value_counts()).reset_index()[:10]\n",
    "bigram = (pd.Series(nltk.ngrams(tokens_clean, 2)).value_counts()).reset_index()[:10]\n",
    "trigram = (pd.Series(nltk.ngrams(tokens_clean, 3)).value_counts()).reset_index()[:10]\n",
    "\n",
    "print(unigram[:10], bigram[:10], trigram[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram['token'] = unigram['index'].apply(lambda x: x[0])\n",
    "\n",
    "sns.barplot(\n",
    "    x='count',\n",
    "    y='token',\n",
    "    data=unigram,\n",
    "    orient='h',\n",
    "    palette=[default_plot_colour],\n",
    "    hue='token',\n",
    "    legend=False\n",
    ").set(title=\"Most Common Unigrams after Preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram['token'] = bigram['index'].apply(lambda x: x[0])\n",
    "\n",
    "sns.barplot(\n",
    "    x='count',\n",
    "    y='token',\n",
    "    data=bigram,\n",
    "    orient='h',\n",
    "    palette=[default_plot_colour],\n",
    "    hue='token',\n",
    "    legend=False\n",
    ").set(title=\"Most Common bigrams after Preprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram['token'] = trigram['index'].apply(lambda x: x[0])\n",
    "\n",
    "sns.barplot(\n",
    "    x='count',\n",
    "    y='token',\n",
    "    data=trigram,\n",
    "    orient='h',\n",
    "    palette=[default_plot_colour],\n",
    "    hue='token',\n",
    "    legend=False\n",
    ").set(title=\"Most Common trigrams after Preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vader_sentiment_score'] = data['text'].apply(lambda x: vader_sentiment.polarity_scores(x)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1, -0.1, 0.1, 1]\n",
    "names = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vader_sentiment_label'] = pd.cut(data['vader_sentiment_score'], bins, labels=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['vader_sentiment_label'].value_counts().plot(kind='bar', color=default_plot_colour)\n",
    "plt.title('Sentiment Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(\n",
    "    x='fake_or_factual',\n",
    "    hue='vader_sentiment_label',\n",
    "    palette = sns.color_palette(\"hls\"),\n",
    "    data=data\n",
    ").set(title=\"Sentiment Distribution by Fake vs Factual News\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_news_text = data[data['fake_or_factual'] == 'Fake News']['text_clean'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_fake = corpora.Dictionary(fake_news_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_fake = [dictionary_fake.doc2bow(doc) for doc in fake_news_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_values = []\n",
    "model_list = []\n",
    "\n",
    "min_topics = 2\n",
    "max_topics = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topics_i in range(min_topics, max_topics):\n",
    "    model = gensim.models.LdaModel(doc_term_fake, num_topics=num_topics_i, id2word=dictionary_fake)\n",
    "    model_list.append(model)\n",
    "    coherence_model = CoherenceModel(model=model, texts=fake_news_text, dictionary=dictionary_fake, coherence='c_v')\n",
    "    coherence_values.append(coherence_model.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(min_topics, max_topics), coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.title(\"Coherence Score by Number of Topics\")\n",
    "plt.legend([\"Coherence Values\"], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the num of topics based on the coherence score above\n",
    "num_topics_lda = 4\n",
    "lda_model = gensim.models.LdaModel(doc_term_fake, num_topics=num_topics_lda, id2word=dictionary_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics(num_topics= num_topics_lda, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_corpus(doc_term_matrix):\n",
    "    tfidf = TfidfModel(corpus = doc_term_matrix, normalize=True)\n",
    "    corpus_tfidf = tfidf[doc_term_matrix]\n",
    "    return corpus_tfidf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coherent_scores(corpus, dictionary, text, min_topics, max_topics):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "\n",
    "    for num_topics_i in range(min_topics, max_topics + 1):\n",
    "        model = gensim.models.LsiModel(corpus, num_topics=num_topics_i, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherence_model = CoherenceModel(model=model, texts=text, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherence_model.get_coherence())\n",
    "\n",
    "    plt.plot(range(min_topics, max_topics + 1), coherence_values)\n",
    "    plt.xlabel(\"Number of Topics\")\n",
    "    plt.ylabel(\"Coherence Score\")\n",
    "    plt.title(\"Coherence Score by Number of Topics\")\n",
    "    plt.legend([\"Coherence Values\"], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf_fake = tfidf_corpus(doc_term_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_coherent_scores(corpus_tfidf_fake, dictionary_fake, fake_news_text, min_topics=2, max_topics=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the final model with the number of topics chosen based on the coherence score\n",
    "num_topics_lsa = 3\n",
    "lsa_model = LsiModel(corpus_tfidf_fake, num_topics=num_topics_lsa, id2word=dictionary_fake)\n",
    "\n",
    "lsa_model.print_topics(num_topics=num_topics_lsa, num_words=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [','.join(map(str, l)) for l in data['text_clean']]\n",
    "Y = data['fake_or_factual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer_fit = count_vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = pd.DataFrame(count_vectorizer_fit.toarray(), columns=count_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(bag_of_words, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = LogisticRegression(random_state=0).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction_logistic_regression = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_prediction_logistic_regression, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_prediction_logistic_regression, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine_model = SGDClassifier(random_state=0).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction_svm = support_vector_machine_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_prediction_svm, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_prediction_svm, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
